# CS231n: Assignment Solutions (2025)

**Stanford University â€” Spring 2025**  

---

## About

### Overview
This repository contains **solutions for the CS231n assignments (Spring 2025)**.  
Each notebook provides clear explanations for inline questions and concise, well-commented code implementations.  
The goal is to offer minimal yet complete solutions for key deep learning concepts.

---

## Main sources (official)

- [Course page](http://cs231n.stanford.edu/)
- [Assignments](http://cs231n.github.io/assignments2025/)
- [Lecture notes](http://cs231n.github.io/)
- [Lecture videos (2025)](https://www.youtube.com/@stanford-cs231n)

---

## Solutions

### **Assignment 1**
- [Q1](assignments/assignment1/Q1_knn.ipynb): *k-Nearest Neighbor classifier*
- [Q2](assignments/assignment1/Q2_softmax.ipynb): *Implement a Softmax classifier*
- [Q3](assignments/assignment1/Q3_two_layer_net.ipynb): *Two-Layer Neural Network*
- [Q4](assignments/assignment1/Q4_features.ipynb): *Higher Level Representations: Image Features*
- [Q5](assignments/assignment1/Q5_fully_connected.ipynb): *Training a Fully-Connected Network*

---

### **Assignment 2**
- [Q1](assignments/assignment2/Q1_batchnorm.ipynb): *Batch Normalization*
- [Q2](assignments/assignment2/Q2_dropout.ipynb): *Dropout*
- [Q3](assignments/assignment2/Q3_convnet.ipynb): *Convolutional Neural Networks*
- [Q4](assignments/assignment2/Q4_pytorch_cifar10.ipynb): *PyTorch on CIFAR-10*
- [Q5](assignments/assignment2/Q5_rnn_captioning.ipynb): *Image Captioning with Vanilla RNNs*

---

### **Assignment 3**
- [Q1](assignments/assignment3/Q1_transformer_captioning.ipynb): *Image Captioning with Transformers*
- [Q2](assignments/assignment3/Q2_self_supervised.ipynb): *Self-Supervised Learning for Image Classification*
- [Q3](assignments/assignment3/Q3_diffusion.ipynb): *Denoising Diffusion Probabilistic Models*
- [Q4](assignments/assignment3/Q4_clip_dino.ipynb): *CLIP and DINO*

---

## Running Locally

The original is configured to run on Google Colab, but this version is a local version.
